{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import sklearn\n",
    "\n",
    "\n",
    "li = []\n",
    "def readJSON(path):\n",
    "    '''\n",
    "    This function reads in a filepath to convert JSON into the separate user, game, and data\n",
    "    \n",
    "    Params:\n",
    "        path (string) - filepath that stores JSON data\n",
    "    '''\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        try:\n",
    "            g = d['gameID']\n",
    "        except Exception as e:\n",
    "            g = None\n",
    "        yield u,g,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameCount = defaultdict(int)\n",
    "totalPlayed = 0\n",
    "\n",
    "for user,game,_ in readJSON(\"train.json.gz\"):\n",
    "    gameCount[game] += 1\n",
    "    totalPlayed += 1\n",
    "\n",
    "mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1:\n",
    "\n",
    "c = 0\n",
    "X_train = []\n",
    "X_val = []\n",
    "userGames = defaultdict(set)\n",
    "gameUsers = defaultdict(set)\n",
    "users = set()\n",
    "games = set()\n",
    "for user, game, d in readJSON('train.json.gz'):\n",
    "    userGames[user].add(game)\n",
    "    gameUsers[game].add(user)\n",
    "    users.add(user)\n",
    "    games.add(game)\n",
    "    if c < 165000: \n",
    "        X_train.append(d)\n",
    "    else:\n",
    "        X_val.append(d)\n",
    "    c+=1\n",
    "    \n",
    "X_train = pd.DataFrame(X_train)[['userID', 'gameID']]\n",
    "X_val = pd.DataFrame(X_val)[['userID', 'gameID']]\n",
    "X_val['y'] = np.array([1]*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_didnt_play(uID):\n",
    "    '''\n",
    "    This function takes a userID and returns all games that the user didn't play\n",
    "    \n",
    "    Params:\n",
    "        uID (string) - userID of the data\n",
    "    '''\n",
    "    g = list(userGames[uID])\n",
    "    g_prime = games.copy()\n",
    "    for i in g:\n",
    "        g_prime.remove(i)\n",
    "    return np.random.choice(list(g_prime))\n",
    "\n",
    "negative = []\n",
    "for i in list(X_val['userID']):\n",
    "    negative.append({'userID': i, 'gameID': user_didnt_play(i), 'y': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = pd.DataFrame(negative)\n",
    "X_val = X_val.append(neg).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy - T1': 0.68245}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPlayed/2:\n",
    "        break\n",
    "        \n",
    "predictions = []\n",
    "for g in X_val['gameID']:\n",
    "    if g in return1:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "        \n",
    "{'Accuracy - T1': np.mean(np.array(predictions) == X_val['y'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy - T2': 0.703}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2:\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPlayed/1.5:\n",
    "        break\n",
    "        \n",
    "predictions = []\n",
    "for g in X_val['gameID']:\n",
    "    if g in return1:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "        \n",
    "{'Accuracy - T2': np.mean(np.array(predictions) == X_val['y'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3:\n",
    "def Jaccard(s1, s2):\n",
    "    '''\n",
    "    This function takes two sets and computes the Jaccard Similarity between them\n",
    "    \n",
    "    Params:\n",
    "        s1 (set) - first set to compare\n",
    "        s2 (set) - second set to compare\n",
    "    '''\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.019</th>\n",
       "      <th>0.020</th>\n",
       "      <th>0.021</th>\n",
       "      <th>0.023</th>\n",
       "      <th>0.024</th>\n",
       "      <th>0.025</th>\n",
       "      <th>0.026</th>\n",
       "      <th>0.027</th>\n",
       "      <th>0.028</th>\n",
       "      <th>0.029</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.6267</td>\n",
       "      <td>0.6436</td>\n",
       "      <td>0.6569</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>0.7064</td>\n",
       "      <td>0.7202</td>\n",
       "      <td>0.7303</td>\n",
       "      <td>0.73985</td>\n",
       "      <td>0.75185</td>\n",
       "      <td>0.75855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.06200</td>\n",
       "      <td>0.07740</td>\n",
       "      <td>0.09740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.7432</td>\n",
       "      <td>0.7058</td>\n",
       "      <td>0.6754</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.5588</td>\n",
       "      <td>0.5194</td>\n",
       "      <td>0.4889</td>\n",
       "      <td>0.45830</td>\n",
       "      <td>0.41890</td>\n",
       "      <td>0.38550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BER</th>\n",
       "      <td>0.3733</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.3431</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.2697</td>\n",
       "      <td>0.26015</td>\n",
       "      <td>0.24815</td>\n",
       "      <td>0.24145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0.019   0.020   0.021   0.023   0.024   0.025   0.026    0.027  \\\n",
       "Accuracy  0.6267  0.6436  0.6569  0.6895  0.7064  0.7202  0.7303  0.73985   \n",
       "FNR       0.0034  0.0070  0.0108  0.0216  0.0284  0.0402  0.0505  0.06200   \n",
       "FPR       0.7432  0.7058  0.6754  0.5994  0.5588  0.5194  0.4889  0.45830   \n",
       "BER       0.3733  0.3564  0.3431  0.3105  0.2936  0.2798  0.2697  0.26015   \n",
       "\n",
       "            0.028    0.029  \n",
       "Accuracy  0.75185  0.75855  \n",
       "FNR       0.07740  0.09740  \n",
       "FPR       0.41890  0.38550  \n",
       "BER       0.24815  0.24145  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter = {}\n",
    "for thresh in [0.019, 0.020, 0.021, 0.023, 0.024, 0.025, 0.026, 0.027, 0.028, 0.029]:\n",
    "    preds = []\n",
    "    for i in range(20000):\n",
    "        jaccard_values = []\n",
    "        user, game = X_val.iloc[i, 0], X_val.iloc[i, 1]\n",
    "        gUsers = gameUsers[game]\n",
    "        uGames = userGames[user]\n",
    "        for x in uGames:\n",
    "            if x == game:\n",
    "                continue\n",
    "            jaccard_values.append(Jaccard(gUsers, gameUsers[x]))\n",
    "        if max(jaccard_values) > thresh:\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(0)\n",
    "    fpr = np.sum((np.array(preds)==1) & (X_val['y']==0)) / np.sum(X_val['y']==0)\n",
    "    fnr = np.sum((np.array(preds)==0) & (X_val['y']==1)) / np.sum(X_val['y']==1)\n",
    "    parameter[thresh] = {'Accuracy': np.mean(np.array(preds)==X_val['y']), \\\n",
    "                         'FNR': fnr, 'FPR': fpr, 'BER': 0.5 * (fpr + fnr)}\n",
    "pd.DataFrame(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4:\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPlayed/2:\n",
    "        break\n",
    "        \n",
    "        \n",
    "preds = []\n",
    "for i in range(20000):\n",
    "    jaccard_values = []\n",
    "    user, game = X_val.iloc[i, 0], X_val.iloc[i, 1]\n",
    "    gUsers = gameUsers[game]\n",
    "    uGames = userGames[user]\n",
    "    for x in uGames:\n",
    "        if x == game:\n",
    "            continue\n",
    "        jaccard_values.append(Jaccard(gUsers, gameUsers[x]))\n",
    "    if (max(jaccard_values) > 0.024) & (game in return1):\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6873"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(preds) == X_val['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5:\n",
    "predictions = open(\"predictions_Played.txt\", 'w')\n",
    "for l in open(\"pairs_Played.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "    #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split('-')\n",
    "    gUsers = gameUsers[g]\n",
    "    uGames = userGames[u]\n",
    "    jaccard_values = []\n",
    "    for x in uGames:\n",
    "        if x == game:\n",
    "            continue\n",
    "        else:\n",
    "            jaccard_values.append(Jaccard(gUsers, gameUsers[x]))\n",
    "    if len(jaccard_values) == 0:\n",
    "        predictions.write(u + '-' + g + \",0\\n\")\n",
    "    elif (max(jaccard_values) > 0.024) & (g in return1):\n",
    "        predictions.write(u + '-' + g + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + g + \",0\\n\")\n",
    "        \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6:\n",
    "c = 0\n",
    "X_train = []\n",
    "X_val = []\n",
    "userGames = defaultdict(set)\n",
    "gameUsers = defaultdict(set)\n",
    "users = set()\n",
    "games = set()\n",
    "for user, game, d in readJSON('train_Category.json.gz'):\n",
    "    userGames[user].add(game)\n",
    "    gameUsers[game].add(user)\n",
    "    users.add(user)\n",
    "    games.add(game)\n",
    "    if c < 165000: \n",
    "        X_train.append(d)\n",
    "    else:\n",
    "        X_val.append(d)\n",
    "    c+=1\n",
    "    \n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_val = pd.DataFrame(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(544597, 'the'),\n",
       " (317620, 'and'),\n",
       " (305414, 'a'),\n",
       " (291882, 'to'),\n",
       " (245359, 'game'),\n",
       " (227234, 'of'),\n",
       " (208417, 'is'),\n",
       " (200633, 'you'),\n",
       " (195953, 'i'),\n",
       " (190966, 'it')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "def clean(s):\n",
    "    '''\n",
    "    This function takes a review and cleans the text by removing capitalization and punctuation\n",
    "    \n",
    "    Params:\n",
    "        s (string) - review text\n",
    "    '''\n",
    "    punctuation = set(string.punctuation)\n",
    "    for i in punctuation:\n",
    "        s = s.replace(i, '')\n",
    "    return s.lower()\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(clean)\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "for i in X_train['text']:\n",
    "    for w in i.split():\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7:\n",
    "\n",
    "word = [w for c, w in counts]\n",
    "words = {}\n",
    "for i in range(1000):\n",
    "    words[word[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(data, wo):\n",
    "    '''\n",
    "    This function creates a feature matrix out of our training data.\n",
    "    \n",
    "    Params:\n",
    "        data (pandas.DataFrame) - our dataset\n",
    "        wo (list) - list of top N words occuring in the corpus of reviews\n",
    "    Return:\n",
    "        Returns a feature matrix of the data passed in\n",
    "    '''\n",
    "    encoding = []\n",
    "    for i in data:\n",
    "        feat = [0]*len(wo)\n",
    "        for w in i.split():\n",
    "            if w in wo.keys():\n",
    "                feat[wo[w]] += 1\n",
    "            else:\n",
    "                continue\n",
    "        encoding.append(feat)\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=10000)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.linear_model.LogisticRegression(C=1, max_iter=10000, fit_intercept=True)\n",
    "model.fit(feature(X_train['text'], words), np.array(X_train['genre']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6372"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(model.predict(feature(X_val['text'], words))) == X_val['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8\n",
    "word = [w for c,w in counts]\n",
    "words = {}\n",
    "for i in range(1500):\n",
    "    words[word[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, max_iter=10000)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8 = sklearn.linear_model.LogisticRegression(C=10, max_iter=10000, fit_intercept=True)\n",
    "model8.fit(feature(X_train['text'], words), np.array(X_train['genre']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.649"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(model8.predict(feature(X_val['text'], words))) == X_val['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "categories = {'Action': 1, 'Strategy': 2, 'RPG': 3, 'Adventure': 4, 'Sports': 5}\n",
    "predictions.write('userID-reviewID,prediction\\n')\n",
    "test_data = []\n",
    "users_and_reviewID = []\n",
    "for user,game,d in readJSON('test_Category.json.gz'):\n",
    "    test_data.append(d['text'])\n",
    "    users_and_reviewID.append((user, d['reviewID']))\n",
    "    \n",
    "p = model8.predict(feature(test_data, words))\n",
    "\n",
    "for i in range(len(p)):\n",
    "    predictions.write(users_and_reviewID[i][0] + '-' + users_and_reviewID[i][1] + ',' + str(categories[p[i]]) + \"\\n\")\n",
    "        \n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
